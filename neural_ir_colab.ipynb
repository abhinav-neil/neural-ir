{"cells":[{"cell_type":"markdown","metadata":{"id":"g9UZ5cfxGY8Q"},"source":["#1. Setting up the enviroments "]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LUmuKS4RRLYd","executionInfo":{"status":"ok","timestamp":1677668504591,"user_tz":-60,"elapsed":28576,"user":{"displayName":"Abhinav Bhuyan","userId":"03657681414650155581"}},"outputId":"abf4d87c-4eb4-43a2-dbc8-cdcd1c355c38"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"gqMpGiSYHI3j"},"source":["##1.1  Change runtime type\n","\n","Before start, you have to  change the Runtime type of this colab to GPU.\n","To do so, you can go to **Runtime** -> **Change runtime type**  and select **GPU**."]},{"cell_type":"markdown","metadata":{"id":"bioHuGfoF1tZ"},"source":["#2. Train and evaluate"]},{"cell_type":"markdown","metadata":{"id":"hNflD7z_H8HM"},"source":["## 2.1 Training "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6An5g74MF7tj"},"outputs":[],"source":["!python -m neural_ir.train --train_batch_size 128 --eval_batch_size 128 ce"]},{"cell_type":"markdown","metadata":{"id":"XeinjLMiIIzg"},"source":["## 2.2 Prediction "]},{"cell_type":"code","execution_count":10,"metadata":{"id":"1xUWlbSSH6ha","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677718258107,"user_tz":-60,"elapsed":45557,"user":{"displayName":"Abhinav Bhuyan","userId":"03657681414650155581"}},"outputId":"c9e21e6b-7597-4736-a10a-42442f91b2bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-03-02 00:50:14.213289: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-03-02 00:50:14.414888: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-03-02 00:50:15.250149: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-03-02 00:50:15.250239: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-03-02 00:50:15.250257: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","reading pairs from collection.tsv: 100% 96270/96270 [00:00<00:00, 769772.39it/s]\n","reading pairs from test_queries.tsv: 100% 500/500 [00:00<00:00, 1580370.76it/s]\n","Reading pairs from data/test_bm25.trec: 492626it [00:00, 640493.54it/s]\n","Writing run file to output/ce/test_run.trec: 100% 500/500 [00:00<00:00, 6399.77it/s]\n"]}],"source":["!python -m neural_ir.rerank"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}