{"cells":[{"cell_type":"markdown","metadata":{"id":"g9UZ5cfxGY8Q"},"source":["#1. Setting up the enviroments "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44181,"status":"ok","timestamp":1677968218137,"user":{"displayName":"Abhinav Bhuyan","userId":"03657681414650155581"},"user_tz":-60},"id":"LUmuKS4RRLYd","outputId":"605103e0-d01c-4020-a041-664f9a9d2305"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/IR1_A1_part2\n"]}],"source":["# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","# clone repo\n","#!git clone https://{PERSONAL_ACCESS_TOKEN}@github.com/{USERNAME}/{REPO-NAME}.git\n","# change working directory to repo\n","%cd /content/drive/MyDrive/Colab\\ Notebooks/IR1_A1_part2/ \n","# install\n","!pip install -r requirements.txt  > /dev/null"]},{"cell_type":"markdown","metadata":{"id":"bioHuGfoF1tZ"},"source":["#2. Train and evaluate"]},{"cell_type":"markdown","metadata":{"id":"hNflD7z_H8HM"},"source":["## 2.1 Training "]},{"cell_type":"code","execution_count":6,"metadata":{"id":"6An5g74MF7tj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677984189176,"user_tz":-60,"elapsed":4944618,"user":{"displayName":"Abhinav Bhuyan","userId":"03657681414650155581"}},"outputId":"70c5e0b9-356b-4002-b17f-c60ce0a300d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-03-05 01:20:44.863790: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-03-05 01:20:44.999063: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-03-05 01:20:45.732346: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-03-05 01:20:45.732435: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-03-05 01:20:45.732453: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","reading triplets from train_triplets.tsv: 100% 96922/96922 [00:00<00:00, 449908.12it/s]\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","max_steps is given, it will override any value given in num_train_epochs\n","Using cuda_amp half precision backend\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 96922\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4000\n","  Number of trainable parameters = 66362880\n","  2% 100/4000 [00:17<10:23,  6.25it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:41<00:00, 30.57it/s]\n","{'eval_nDCG@10': 0.003989780533604438, 'eval_RR@10': 0.0017499999999999998, 'eval_R@1000': 0.9825, 'epoch': 0.07}\n","  2% 100/4000 [01:58<10:23,  6.25it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-100\n","Configuration saved in output/your_creativity/model/checkpoint-100/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-100/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-100/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-100/special_tokens_map.json\n","  5% 200/4000 [02:17<09:55,  6.38it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:41<00:00, 30.57it/s]\n","{'eval_nDCG@10': 0.002413126658759655, 'eval_RR@10': 0.0014583333333333332, 'eval_R@1000': 0.9825, 'epoch': 0.13}\n","  5% 200/4000 [03:59<09:55,  6.38it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-200\n","Configuration saved in output/your_creativity/model/checkpoint-200/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-200/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-200/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-200/special_tokens_map.json\n","  8% 300/4000 [04:17<09:35,  6.43it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:41<00:00, 30.60it/s]\n","{'eval_nDCG@10': 0.004087646826539674, 'eval_RR@10': 0.00375, 'eval_R@1000': 0.9825, 'epoch': 0.2}\n","  8% 300/4000 [05:59<09:35,  6.43it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-300\n","Configuration saved in output/your_creativity/model/checkpoint-300/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-300/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-300/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-300/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-100] due to args.save_total_limit\n"," 10% 400/4000 [06:17<09:07,  6.58it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:41<00:00, 30.47it/s]\n","{'eval_nDCG@10': 0.005582474362248551, 'eval_RR@10': 0.002847222222222222, 'eval_R@1000': 0.9825, 'epoch': 0.26}\n"," 10% 400/4000 [07:59<09:07,  6.58it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-400\n","Configuration saved in output/your_creativity/model/checkpoint-400/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-400/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-400/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-400/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-200] due to args.save_total_limit\n","{'loss': 636999.552, 'learning_rate': 4.79e-06, 'epoch': 0.33}\n"," 12% 500/4000 [08:17<09:05,  6.41it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.38it/s]\n","{'eval_nDCG@10': 0.005, 'eval_RR@10': 0.005, 'eval_R@1000': 0.9825, 'epoch': 0.33}\n"," 12% 500/4000 [09:59<09:05,  6.41it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-500\n","Configuration saved in output/your_creativity/model/checkpoint-500/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-500/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-300] due to args.save_total_limit\n"," 15% 600/4000 [10:18<08:38,  6.55it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.39it/s]\n","{'eval_nDCG@10': 0.005, 'eval_RR@10': 0.005, 'eval_R@1000': 0.9825, 'epoch': 0.4}\n"," 15% 600/4000 [12:00<08:38,  6.55it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-600\n","Configuration saved in output/your_creativity/model/checkpoint-600/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-600/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-600/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-600/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-400] due to args.save_total_limit\n"," 18% 700/4000 [12:18<08:31,  6.46it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.37it/s]\n","{'eval_nDCG@10': 0.01153443980344592, 'eval_RR@10': 0.008347222222222223, 'eval_R@1000': 0.9825, 'epoch': 0.46}\n"," 18% 700/4000 [14:01<08:31,  6.46it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-700\n","Configuration saved in output/your_creativity/model/checkpoint-700/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-700/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-700/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-700/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-500] due to args.save_total_limit\n"," 20% 800/4000 [14:20<08:37,  6.19it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:41<00:00, 30.47it/s]\n","{'eval_nDCG@10': 0.016047140716674287, 'eval_RR@10': 0.010464285714285712, 'eval_R@1000': 0.9825, 'epoch': 0.53}\n"," 20% 800/4000 [16:02<08:37,  6.19it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-800\n","Configuration saved in output/your_creativity/model/checkpoint-800/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-800/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-800/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-800/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-600] due to args.save_total_limit\n"," 22% 900/4000 [16:20<08:10,  6.32it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.43it/s]\n","{'eval_nDCG@10': 0.01994621001383491, 'eval_RR@10': 0.01613888888888889, 'eval_R@1000': 0.9825, 'epoch': 0.59}\n"," 22% 900/4000 [18:03<08:10,  6.32it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-900\n","Configuration saved in output/your_creativity/model/checkpoint-900/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-900/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-900/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-900/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-700] due to args.save_total_limit\n","{'loss': 559737.152, 'learning_rate': 9.790000000000001e-06, 'epoch': 0.66}\n"," 25% 1000/4000 [18:21<08:15,  6.06it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.22it/s]\n","{'eval_nDCG@10': 0.02027621225823451, 'eval_RR@10': 0.014603174603174604, 'eval_R@1000': 0.9825, 'epoch': 0.66}\n"," 25% 1000/4000 [20:04<08:15,  6.06it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-1000\n","Configuration saved in output/your_creativity/model/checkpoint-1000/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-1000/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-800] due to args.save_total_limit\n"," 28% 1100/4000 [20:22<07:51,  6.15it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.30it/s]\n","{'eval_nDCG@10': 0.028064518803027214, 'eval_RR@10': 0.025083333333333332, 'eval_R@1000': 0.9825, 'epoch': 0.73}\n"," 28% 1100/4000 [22:05<07:51,  6.15it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-1100\n","Configuration saved in output/your_creativity/model/checkpoint-1100/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-1100/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-1100/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-1100/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-900] due to args.save_total_limit\n"," 30% 1200/4000 [22:23<07:32,  6.18it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.41it/s]\n","{'eval_nDCG@10': 0.018442306989740306, 'eval_RR@10': 0.013505952380952382, 'eval_R@1000': 0.9825, 'epoch': 0.79}\n"," 30% 1200/4000 [24:05<07:32,  6.18it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-1200\n","Configuration saved in output/your_creativity/model/checkpoint-1200/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-1200/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-1200/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-1200/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-1000] due to args.save_total_limit\n"," 32% 1300/4000 [24:23<07:04,  6.36it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:41<00:00, 30.52it/s]\n","{'eval_nDCG@10': 0.012153382790366964, 'eval_RR@10': 0.01125, 'eval_R@1000': 0.9825, 'epoch': 0.86}\n"," 32% 1300/4000 [26:05<07:04,  6.36it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-1300\n","Configuration saved in output/your_creativity/model/checkpoint-1300/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-1300/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-1300/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-1300/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-1200] due to args.save_total_limit\n"," 35% 1400/4000 [26:23<07:05,  6.11it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:41<00:00, 30.52it/s]\n","{'eval_nDCG@10': 0.011445324131589439, 'eval_RR@10': 0.0105, 'eval_R@1000': 0.9825, 'epoch': 0.92}\n"," 35% 1400/4000 [28:05<07:05,  6.11it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-1400\n","Configuration saved in output/your_creativity/model/checkpoint-1400/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-1400/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-1400/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-1400/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-1300] due to args.save_total_limit\n","{'loss': 548153.472, 'learning_rate': 1.4779999999999999e-05, 'epoch': 0.99}\n"," 38% 1500/4000 [28:23<06:14,  6.68it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.25it/s]\n","{'eval_nDCG@10': 0.01658750850366097, 'eval_RR@10': 0.013589285714285713, 'eval_R@1000': 0.9825, 'epoch': 0.99}\n"," 38% 1500/4000 [30:06<06:14,  6.68it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-1500\n","Configuration saved in output/your_creativity/model/checkpoint-1500/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-1500/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-1400] due to args.save_total_limit\n"," 40% 1600/4000 [30:24<06:20,  6.32it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.24it/s]\n","{'eval_nDCG@10': 0.013945324131589438, 'eval_RR@10': 0.012166666666666668, 'eval_R@1000': 0.9825, 'epoch': 1.06}\n"," 40% 1600/4000 [32:07<06:20,  6.32it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-1600\n","Configuration saved in output/your_creativity/model/checkpoint-1600/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-1600/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-1600/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-1600/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-1500] due to args.save_total_limit\n"," 42% 1700/4000 [32:25<06:07,  6.26it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.27it/s]\n","{'eval_nDCG@10': 0.010219118754194257, 'eval_RR@10': 0.01125, 'eval_R@1000': 0.9825, 'epoch': 1.12}\n"," 42% 1700/4000 [34:08<06:07,  6.26it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-1700\n","Configuration saved in output/your_creativity/model/checkpoint-1700/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-1700/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-1700/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-1700/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-1600] due to args.save_total_limit\n"," 45% 1800/4000 [34:26<06:09,  5.95it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:43<00:00, 30.03it/s]\n","{'eval_nDCG@10': 0.010397373840962277, 'eval_RR@10': 0.007589285714285714, 'eval_R@1000': 0.9825, 'epoch': 1.19}\n"," 45% 1800/4000 [36:10<06:09,  5.95it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-1800\n","Configuration saved in output/your_creativity/model/checkpoint-1800/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-1800/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-1800/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-1800/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-1700] due to args.save_total_limit\n"," 48% 1900/4000 [36:28<05:30,  6.36it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.25it/s]\n","{'eval_nDCG@10': 0.01030748476789092, 'eval_RR@10': 0.006714285714285715, 'eval_R@1000': 0.9825, 'epoch': 1.25}\n"," 48% 1900/4000 [38:11<05:30,  6.36it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-1900\n","Configuration saved in output/your_creativity/model/checkpoint-1900/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-1900/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-1900/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-1900/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-1800] due to args.save_total_limit\n","{'loss': 550821.888, 'learning_rate': 1.976e-05, 'epoch': 1.32}\n"," 50% 2000/4000 [38:29<05:21,  6.22it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:43<00:00, 30.11it/s]\n","{'eval_nDCG@10': 0.016974698224890918, 'eval_RR@10': 0.014464285714285714, 'eval_R@1000': 0.9825, 'epoch': 1.32}\n"," 50% 2000/4000 [40:12<05:21,  6.22it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-2000\n","Configuration saved in output/your_creativity/model/checkpoint-2000/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-2000/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-1900] due to args.save_total_limit\n"," 52% 2100/4000 [40:30<05:05,  6.22it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.36it/s]\n","{'eval_nDCG@10': 0.012257000137921352, 'eval_RR@10': 0.008214285714285714, 'eval_R@1000': 0.9825, 'epoch': 1.39}\n"," 52% 2100/4000 [42:13<05:05,  6.22it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-2100\n","Configuration saved in output/your_creativity/model/checkpoint-2100/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-2100/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-2100/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-2100/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-2000] due to args.save_total_limit\n"," 55% 2200/4000 [42:31<05:01,  5.97it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.29it/s]\n","{'eval_nDCG@10': 0.017913088575805928, 'eval_RR@10': 0.013839285714285714, 'eval_R@1000': 0.9825, 'epoch': 1.45}\n"," 55% 2200/4000 [44:14<05:01,  5.97it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-2200\n","Configuration saved in output/your_creativity/model/checkpoint-2200/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-2200/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-2200/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-2200/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-2100] due to args.save_total_limit\n"," 57% 2300/4000 [44:32<04:31,  6.26it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.33it/s]\n","{'eval_nDCG@10': 0.01303519473901208, 'eval_RR@10': 0.00938095238095238, 'eval_R@1000': 0.9825, 'epoch': 1.52}\n"," 57% 2300/4000 [46:14<04:31,  6.26it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-2300\n","Configuration saved in output/your_creativity/model/checkpoint-2300/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-2300/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-2300/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-2300/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-2200] due to args.save_total_limit\n"," 60% 2400/4000 [46:32<04:06,  6.49it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.19it/s]\n","{'eval_nDCG@10': 0.014742295594396961, 'eval_RR@10': 0.011416666666666665, 'eval_R@1000': 0.9825, 'epoch': 1.58}\n"," 60% 2400/4000 [48:16<04:06,  6.49it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-2400\n","Configuration saved in output/your_creativity/model/checkpoint-2400/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-2400/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-2400/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-2400/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-2300] due to args.save_total_limit\n","{'loss': 547411.52, 'learning_rate': 2.4740000000000004e-05, 'epoch': 1.65}\n"," 62% 2500/4000 [48:34<03:56,  6.34it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.26it/s]\n","{'eval_nDCG@10': 0.007182431989799173, 'eval_RR@10': 0.004125, 'eval_R@1000': 0.9825, 'epoch': 1.65}\n"," 62% 2500/4000 [50:17<03:56,  6.34it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-2500\n","Configuration saved in output/your_creativity/model/checkpoint-2500/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-2500/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-2400] due to args.save_total_limit\n"," 65% 2600/4000 [50:35<03:45,  6.21it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.22it/s]\n","{'eval_nDCG@10': 0.015425997691925328, 'eval_RR@10': 0.009797619047619048, 'eval_R@1000': 0.9825, 'epoch': 1.72}\n"," 65% 2600/4000 [52:18<03:45,  6.21it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-2600\n","Configuration saved in output/your_creativity/model/checkpoint-2600/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-2600/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-2600/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-2600/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-2500] due to args.save_total_limit\n"," 68% 2700/4000 [52:36<03:16,  6.63it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.23it/s]\n","{'eval_nDCG@10': 0.012153382790366964, 'eval_RR@10': 0.009583333333333333, 'eval_R@1000': 0.9825, 'epoch': 1.78}\n"," 68% 2700/4000 [54:19<03:16,  6.63it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-2700\n","Configuration saved in output/your_creativity/model/checkpoint-2700/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-2700/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-2700/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-2700/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-2600] due to args.save_total_limit\n"," 70% 2800/4000 [54:37<03:16,  6.09it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.37it/s]\n","{'eval_nDCG@10': 0.0042810359355401105, 'eval_RR@10': 0.0025, 'eval_R@1000': 0.9825, 'epoch': 1.85}\n"," 70% 2800/4000 [56:20<03:16,  6.09it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-2800\n","Configuration saved in output/your_creativity/model/checkpoint-2800/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-2800/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-2800/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-2800/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-2700] due to args.save_total_limit\n"," 72% 2900/4000 [56:38<02:58,  6.16it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.35it/s]\n","{'eval_nDCG@10': 0.014183405065087924, 'eval_RR@10': 0.009561507936507936, 'eval_R@1000': 0.9825, 'epoch': 1.91}\n"," 72% 2900/4000 [58:21<02:58,  6.16it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-2900\n","Configuration saved in output/your_creativity/model/checkpoint-2900/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-2900/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-2900/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-2900/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-2800] due to args.save_total_limit\n","{'loss': 556370.432, 'learning_rate': 2.974e-05, 'epoch': 1.98}\n"," 75% 3000/4000 [58:38<02:43,  6.11it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.30it/s]\n","{'eval_nDCG@10': 0.010035349428746452, 'eval_RR@10': 0.005464285714285714, 'eval_R@1000': 0.9825, 'epoch': 1.98}\n"," 75% 3000/4000 [1:00:21<02:43,  6.11it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-3000\n","Configuration saved in output/your_creativity/model/checkpoint-3000/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-3000/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-2900] due to args.save_total_limit\n"," 78% 3100/4000 [1:00:39<02:21,  6.35it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.29it/s]\n","{'eval_nDCG@10': 0.012106235370893649, 'eval_RR@10': 0.008353174603174602, 'eval_R@1000': 0.9825, 'epoch': 2.05}\n"," 78% 3100/4000 [1:02:22<02:21,  6.35it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-3100\n","Configuration saved in output/your_creativity/model/checkpoint-3100/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-3100/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-3100/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-3100/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-3000] due to args.save_total_limit\n"," 80% 3200/4000 [1:02:41<02:13,  6.01it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.31it/s]\n","{'eval_nDCG@10': 0.016309297535714574, 'eval_RR@10': 0.012083333333333333, 'eval_R@1000': 0.9825, 'epoch': 2.11}\n"," 80% 3200/4000 [1:04:23<02:13,  6.01it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-3200\n","Configuration saved in output/your_creativity/model/checkpoint-3200/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-3200/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-3200/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-3200/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-3100] due to args.save_total_limit\n"," 82% 3300/4000 [1:04:41<01:48,  6.45it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:43<00:00, 30.12it/s]\n","{'eval_nDCG@10': 0.0064453241315894395, 'eval_RR@10': 0.0055000000000000005, 'eval_R@1000': 0.9825, 'epoch': 2.18}\n"," 82% 3300/4000 [1:06:25<01:48,  6.45it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-3300\n","Configuration saved in output/your_creativity/model/checkpoint-3300/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-3300/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-3300/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-3300/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-3200] due to args.save_total_limit\n"," 85% 3400/4000 [1:06:43<01:37,  6.17it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.23it/s]\n","{'eval_nDCG@10': 0.014574100840379774, 'eval_RR@10': 0.008351190476190476, 'eval_R@1000': 0.9825, 'epoch': 2.24}\n"," 85% 3400/4000 [1:08:26<01:37,  6.17it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-3400\n","Configuration saved in output/your_creativity/model/checkpoint-3400/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-3400/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-3400/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-3400/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-3300] due to args.save_total_limit\n","{'loss': 554857.024, 'learning_rate': 3.474e-05, 'epoch': 2.31}\n"," 88% 3500/4000 [1:08:44<01:21,  6.10it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.32it/s]\n","{'eval_nDCG@10': 0.016351451310418732, 'eval_RR@10': 0.010603174603174604, 'eval_R@1000': 0.9825, 'epoch': 2.31}\n"," 88% 3500/4000 [1:10:27<01:21,  6.10it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-3500\n","Configuration saved in output/your_creativity/model/checkpoint-3500/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-3500/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-3400] due to args.save_total_limit\n"," 90% 3600/4000 [1:10:45<01:03,  6.29it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.24it/s]\n","{'eval_nDCG@10': 0.008732505606709426, 'eval_RR@10': 0.00513095238095238, 'eval_R@1000': 0.9825, 'epoch': 2.38}\n"," 90% 3600/4000 [1:12:28<01:03,  6.29it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-3600\n","Configuration saved in output/your_creativity/model/checkpoint-3600/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-3600/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-3600/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-3600/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-3500] due to args.save_total_limit\n"," 92% 3700/4000 [1:12:46<00:48,  6.21it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:41<00:00, 30.48it/s]\n","{'eval_nDCG@10': 0.013239109158450035, 'eval_RR@10': 0.006246031746031745, 'eval_R@1000': 0.9825, 'epoch': 2.44}\n"," 92% 3700/4000 [1:14:28<00:48,  6.21it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-3700\n","Configuration saved in output/your_creativity/model/checkpoint-3700/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-3700/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-3700/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-3700/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-3600] due to args.save_total_limit\n"," 95% 3800/4000 [1:14:46<00:32,  6.17it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.44it/s]\n","{'eval_nDCG@10': 0.013367158460049811, 'eval_RR@10': 0.007305555555555555, 'eval_R@1000': 0.9825, 'epoch': 2.51}\n"," 95% 3800/4000 [1:16:28<00:32,  6.17it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-3800\n","Configuration saved in output/your_creativity/model/checkpoint-3800/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-3800/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-3800/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-3800/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-3700] due to args.save_total_limit\n"," 98% 3900/4000 [1:16:46<00:15,  6.28it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:41<00:00, 30.52it/s]\n","{'eval_nDCG@10': 0.007393026733796216, 'eval_RR@10': 0.003714285714285714, 'eval_R@1000': 0.9825, 'epoch': 2.57}\n"," 98% 3900/4000 [1:18:28<00:15,  6.28it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-3900\n","Configuration saved in output/your_creativity/model/checkpoint-3900/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-3900/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-3900/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-3900/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-3800] due to args.save_total_limit\n","{'loss': 548774.976, 'learning_rate': 3.974e-05, 'epoch': 2.64}\n","100% 4000/4000 [1:18:46<00:00,  6.24it/s]INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:42<00:00, 30.27it/s]\n","{'eval_nDCG@10': 0.01655801307890681, 'eval_RR@10': 0.01176984126984127, 'eval_R@1000': 0.9825, 'epoch': 2.64}\n","100% 4000/4000 [1:20:29<00:00,  6.24it/s]INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model/checkpoint-4000\n","Configuration saved in output/your_creativity/model/checkpoint-4000/config.json\n","Model weights saved in output/your_creativity/model/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/checkpoint-4000/special_tokens_map.json\n","Deleting older checkpoint [output/your_creativity/model/checkpoint-3900] due to args.save_total_limit\n","INFO:neural_ir.trainer.hf_trainer:Running evaluation\n","Evaluating the model: 100% 3106/3106 [01:43<00:00, 30.12it/s]\n","{'eval_nDCG@10': 0.01655801307890681, 'eval_RR@10': 0.01176984126984127, 'eval_R@1000': 0.9825, 'epoch': 2.64}\n","100% 4000/4000 [1:22:15<00:00,  6.24it/s]\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","INFO:neural_ir.trainer.hf_trainer:Loading best model from output/your_creativity/model/checkpoint-1100 (score: 0.025083333333333332).\n","{'train_runtime': 4935.4102, 'train_samples_per_second': 51.87, 'train_steps_per_second': 0.81, 'train_loss': 562890.752, 'epoch': 2.64}\n","100% 4000/4000 [1:22:15<00:00,  1.23s/it]\n","INFO:neural_ir.trainer.hf_trainer:Saving model checkpoint to output/your_creativity/model\n","Configuration saved in output/your_creativity/model/config.json\n","Model weights saved in output/your_creativity/model/pytorch_model.bin\n","tokenizer config file saved in output/your_creativity/model/tokenizer_config.json\n","Special tokens file saved in output/your_creativity/model/special_tokens_map.json\n"]}],"source":["!python -m neural_ir.train --train_batch_size 64 --eval_batch_size 64 your_creativity"]},{"cell_type":"markdown","metadata":{"id":"XeinjLMiIIzg"},"source":["## 2.2 Prediction "]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1xUWlbSSH6ha","executionInfo":{"status":"ok","timestamp":1677984962695,"user_tz":-60,"elapsed":76545,"user":{"displayName":"Abhinav Bhuyan","userId":"03657681414650155581"}},"outputId":"8cf572e7-55a7-43fd-c891-327c4e404cf3"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-03-05 02:54:49.383306: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-03-05 02:54:49.539886: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-03-05 02:54:50.337099: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-03-05 02:54:50.337190: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-03-05 02:54:50.337208: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","reading pairs from collection.tsv: 100% 96270/96270 [00:00<00:00, 794969.44it/s]\n","reading pairs from test_queries.tsv: 100% 500/500 [00:00<00:00, 1243862.40it/s]\n","Encoding documents: 100% 6017/6017 [01:02<00:00, 95.99it/s]\n","Encoding queries and search: 100% 32/32 [00:02<00:00, 11.73it/s]\n","Writing run file to output/your_creativity/test_run.trec: 100% 500/500 [00:00<00:00, 547.33it/s]\n"]}],"source":["!python -m neural_ir.rank_your_creativity\n","# !python -m neural_ir.evaluate sparse # eval"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}